{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A notebook for the classification of the MNIST fashion dataset.\n",
    "\n",
    "I used Sequential Convolutional Neural Networks (CNN) model using Keras and tensorflow as a backend.\n",
    "\n",
    "I re-Run the model **10 times** for taking averages. \n",
    "\n",
    "\n",
    "\n",
    "Result : |Training Accuracy | Dev(Validation) Accuracy| Testing Accuracy |\n",
    "---------------------------------------------------------------------|\n",
    "         | 93.196 %          | 91.864 %               | 92.159 %          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size     = 64\n",
    "nb_classes     = 10\n",
    "nb_ephochs     = 50\n",
    "img_rows, img_cols = 28,28\n",
    "nb_filters     = 32\n",
    "pool_size      = 2\n",
    "kernel_size    = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_dim_ordering() == 'th':\n",
    "    input_shape = (1,img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows,img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv('input_data/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('input_data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clothes = {0: 'T-shirt/top',\n",
    "           1: 'Trouser',\n",
    "           2: 'Pullover',\n",
    "           3: 'Dress',\n",
    "           4: 'Coat',\n",
    "           5: 'Sandal',\n",
    "           6: 'Shirt',\n",
    "           7: 'Sneaker',\n",
    "           8: 'Bag',\n",
    "           9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAJoCAYAAAB7txeYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAVTJABAACAiv8PxeIxJCXV0YEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ffbbeb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 4,figsize=(10,10))\n",
    "for row in axes:\n",
    "    for axe in row:\n",
    "        index = np.random.randint(10000)\n",
    "        img = data_train.iloc[index, 1:].values.reshape((28, 28))\n",
    "        obj = data_train.iloc[index, 0]\n",
    "        axe.imshow(img, cmap='gray')\n",
    "        axe.set_title(clothes[obj])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_train.iloc[:,1:].values\n",
    "y = data_train.iloc[:,0].values\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = data_test.iloc[:,1:].values\n",
    "y_test = data_test.iloc[:,0]\n",
    "y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Data +  Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = X_train  / 255\n",
    "X_val   = X_val   / 255\n",
    "X_test  = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(),X_val.max(), X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(),X_val.min(), X_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "## Now we need to follow the following steps:\n",
    "    \n",
    "    1. Convolution \n",
    "    2. Max Pooling\n",
    "    3. Convolution\n",
    "    4. Max pooling\n",
    "    5. Dropout\n",
    "    6  Flattening\n",
    "    7. Full Connection (Dense)\n",
    "    8. Dropout\n",
    "    9. Full Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(nb_filters,kernel_size,input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters= nb_filters,kernel_size=(kernel_size,kernel_size),input_shape = input_shape,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n",
    "\n",
    "    model.add(Convolution2D(filters=nb_filters, kernel_size=(kernel_size,kernel_size),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(output_dim = 128 , activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim = nb_classes, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "#model.compile(loss = keras.losses.categorical_crossentropy, optimizer= keras.optimizers.adam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agebresi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\agebresi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = model_architecture(nb_filters,kernel_size,input_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########    Run 1    ######## \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agebresi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\agebresi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.6667 - acc: 0.7591 - val_loss: 0.4146 - val_acc: 0.8460\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.4517 - acc: 0.8351 - val_loss: 0.3557 - val_acc: 0.8742\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.4002 - acc: 0.8554 - val_loss: 0.3229 - val_acc: 0.8848\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.3706 - acc: 0.8650 - val_loss: 0.3042 - val_acc: 0.8915\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.3475 - acc: 0.8736 - val_loss: 0.3012 - val_acc: 0.8898\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.3313 - acc: 0.8795 - val_loss: 0.2893 - val_acc: 0.8912\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.3195 - acc: 0.8827 - val_loss: 0.2807 - val_acc: 0.8966\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.3055 - acc: 0.8891 - val_loss: 0.2644 - val_acc: 0.9005\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2926 - acc: 0.8932 - val_loss: 0.2590 - val_acc: 0.9026\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 27s - loss: 0.2887 - acc: 0.8933 - val_loss: 0.2569 - val_acc: 0.9081\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2749 - acc: 0.8981 - val_loss: 0.2530 - val_acc: 0.9048\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2716 - acc: 0.8992 - val_loss: 0.2561 - val_acc: 0.9066\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2643 - acc: 0.9009 - val_loss: 0.2522 - val_acc: 0.9073\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2577 - acc: 0.9047 - val_loss: 0.2431 - val_acc: 0.9117\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2552 - acc: 0.9052 - val_loss: 0.2452 - val_acc: 0.9120\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2473 - acc: 0.9095 - val_loss: 0.2511 - val_acc: 0.9097\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2414 - acc: 0.9089 - val_loss: 0.2503 - val_acc: 0.9086\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2401 - acc: 0.9102 - val_loss: 0.2411 - val_acc: 0.9128\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2384 - acc: 0.9113 - val_loss: 0.2368 - val_acc: 0.9148\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2316 - acc: 0.9125 - val_loss: 0.2404 - val_acc: 0.9142\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2297 - acc: 0.9135 - val_loss: 0.2376 - val_acc: 0.9157\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2277 - acc: 0.9139 - val_loss: 0.2483 - val_acc: 0.9108\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2239 - acc: 0.9155 - val_loss: 0.2430 - val_acc: 0.9131\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2235 - acc: 0.9147 - val_loss: 0.2496 - val_acc: 0.9099\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2208 - acc: 0.9171 - val_loss: 0.2428 - val_acc: 0.9167\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2138 - acc: 0.9196 - val_loss: 0.2473 - val_acc: 0.9110\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2094 - acc: 0.9206 - val_loss: 0.2393 - val_acc: 0.9143\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2098 - acc: 0.9206 - val_loss: 0.2379 - val_acc: 0.9165\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2092 - acc: 0.9212 - val_loss: 0.2363 - val_acc: 0.9163\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2065 - acc: 0.9226 - val_loss: 0.2448 - val_acc: 0.9145\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2027 - acc: 0.9227 - val_loss: 0.2626 - val_acc: 0.9068\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.1994 - acc: 0.9237 - val_loss: 0.2473 - val_acc: 0.9127\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2016 - acc: 0.9233 - val_loss: 0.2411 - val_acc: 0.9159\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.2001 - acc: 0.9238 - val_loss: 0.2429 - val_acc: 0.9183\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.1975 - acc: 0.9252 - val_loss: 0.2369 - val_acc: 0.9155\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.1971 - acc: 0.9245 - val_loss: 0.2343 - val_acc: 0.9168\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.1934 - acc: 0.9261 - val_loss: 0.2415 - val_acc: 0.9153\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 30s - loss: 0.1930 - acc: 0.9257 - val_loss: 0.2428 - val_acc: 0.9175\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 30s - loss: 0.1964 - acc: 0.9252 - val_loss: 0.2423 - val_acc: 0.9186\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 31s - loss: 0.1906 - acc: 0.9265 - val_loss: 0.2498 - val_acc: 0.9164\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 31s - loss: 0.1893 - acc: 0.9281 - val_loss: 0.2467 - val_acc: 0.9149\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 31s - loss: 0.1888 - acc: 0.9278 - val_loss: 0.2452 - val_acc: 0.9159\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 31s - loss: 0.1841 - acc: 0.9294 - val_loss: 0.2536 - val_acc: 0.9139\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 30s - loss: 0.1827 - acc: 0.9298 - val_loss: 0.2474 - val_acc: 0.9166\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 30s - loss: 0.1840 - acc: 0.9297 - val_loss: 0.2390 - val_acc: 0.9166\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 30s - loss: 0.1820 - acc: 0.9310 - val_loss: 0.2443 - val_acc: 0.9136\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 31s - loss: 0.1800 - acc: 0.9303 - val_loss: 0.2391 - val_acc: 0.9173\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 29s - loss: 0.1827 - acc: 0.9293 - val_loss: 0.2453 - val_acc: 0.9164\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 28s - loss: 0.1791 - acc: 0.9307 - val_loss: 0.2423 - val_acc: 0.9178\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 29s - loss: 0.1744 - acc: 0.9335 - val_loss: 0.2452 - val_acc: 0.9183\n",
      " 9792/10000 [============================>.] - ETA: 0s########    Run 2    ######## \n",
      "\n",
      "########    Run 3    ######## \n",
      "\n",
      "########    Run 4    ######## \n",
      "\n",
      "########    Run 5    ######## \n",
      "\n",
      "########    Run 6    ######## \n",
      "\n",
      "########    Run 7    ######## \n",
      "\n",
      "########    Run 8    ######## \n",
      "\n",
      "########    Run 9    ######## \n",
      "\n",
      "########    Run 10    ######## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_time    = {}\n",
    "training_history = {}\n",
    "testing_history  = {}\n",
    "\n",
    "tranining_acc   = 0.0\n",
    "validation_acc  = 0.0\n",
    "testing_acc     = 0.0\n",
    "for i in range(1,11):\n",
    "    print('########    Run ' + str(i) + '    ######## \\n')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if (i == 1):\n",
    "        verbose = 1\n",
    "    else:\n",
    "        verbose = 0\n",
    "    model = model_architecture(nb_filters,kernel_size,input_shape)\n",
    "    training_history['run_' + str(i)] = model.fit(X_train,y_train,batch_size= batch_size, epochs = nb_ephochs, verbose=verbose, validation_data=(X_val, y_val))\n",
    "    training_time['run_' + str(i)] = time.time() - start_time\n",
    "    tranining_acc  =  tranining_acc  + training_history['run_' + str(i)].history['acc'][-1]\n",
    "    validation_acc =  validation_acc + training_history['run_'  + str(i)].history['val_acc'][-1]\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=verbose)\n",
    "    testing_history['loss run_' + str(i)] = score[0]\n",
    "    testing_history['acc run_'  + str(i)] = score[1]*100\n",
    "    testing_acc = testing_acc + score[1]\n",
    "    \n",
    "    model.save('model_run' + str(i) + '.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_train_acc = []\n",
    "cols_val_acc   = []\n",
    "cols_test_acc  = []\n",
    "accuracy_cols  = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    col_train =  'training_acc_' + 'run_' + str(i) \n",
    "    cols_train_acc.append(col_train)\n",
    "    \n",
    "    col_val = 'val_acc_' + 'run_' + str(i)  \n",
    "    cols_val_acc.append(col_val)\n",
    "    \n",
    "accuracy_cols  = cols_train_acc + cols_val_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_acc_run_1</th>\n",
       "      <th>training_acc_run_2</th>\n",
       "      <th>training_acc_run_3</th>\n",
       "      <th>training_acc_run_4</th>\n",
       "      <th>training_acc_run_5</th>\n",
       "      <th>training_acc_run_6</th>\n",
       "      <th>training_acc_run_7</th>\n",
       "      <th>training_acc_run_8</th>\n",
       "      <th>training_acc_run_9</th>\n",
       "      <th>training_acc_run_10</th>\n",
       "      <th>val_acc_run_1</th>\n",
       "      <th>val_acc_run_2</th>\n",
       "      <th>val_acc_run_3</th>\n",
       "      <th>val_acc_run_4</th>\n",
       "      <th>val_acc_run_5</th>\n",
       "      <th>val_acc_run_6</th>\n",
       "      <th>val_acc_run_7</th>\n",
       "      <th>val_acc_run_8</th>\n",
       "      <th>val_acc_run_9</th>\n",
       "      <th>val_acc_run_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.91</td>\n",
       "      <td>74.54</td>\n",
       "      <td>74.28</td>\n",
       "      <td>74.40</td>\n",
       "      <td>75.65</td>\n",
       "      <td>74.65</td>\n",
       "      <td>74.97</td>\n",
       "      <td>74.16</td>\n",
       "      <td>74.25</td>\n",
       "      <td>75.46</td>\n",
       "      <td>84.60</td>\n",
       "      <td>84.48</td>\n",
       "      <td>84.98</td>\n",
       "      <td>84.40</td>\n",
       "      <td>85.19</td>\n",
       "      <td>84.87</td>\n",
       "      <td>84.28</td>\n",
       "      <td>83.91</td>\n",
       "      <td>83.53</td>\n",
       "      <td>84.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.51</td>\n",
       "      <td>82.93</td>\n",
       "      <td>83.26</td>\n",
       "      <td>82.80</td>\n",
       "      <td>83.95</td>\n",
       "      <td>82.68</td>\n",
       "      <td>83.25</td>\n",
       "      <td>82.69</td>\n",
       "      <td>82.67</td>\n",
       "      <td>83.36</td>\n",
       "      <td>87.42</td>\n",
       "      <td>86.47</td>\n",
       "      <td>87.01</td>\n",
       "      <td>86.93</td>\n",
       "      <td>87.71</td>\n",
       "      <td>86.09</td>\n",
       "      <td>86.92</td>\n",
       "      <td>86.36</td>\n",
       "      <td>86.22</td>\n",
       "      <td>86.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.54</td>\n",
       "      <td>84.93</td>\n",
       "      <td>85.14</td>\n",
       "      <td>84.75</td>\n",
       "      <td>85.67</td>\n",
       "      <td>85.00</td>\n",
       "      <td>85.33</td>\n",
       "      <td>84.95</td>\n",
       "      <td>85.00</td>\n",
       "      <td>85.31</td>\n",
       "      <td>88.48</td>\n",
       "      <td>87.74</td>\n",
       "      <td>87.82</td>\n",
       "      <td>87.58</td>\n",
       "      <td>88.44</td>\n",
       "      <td>88.53</td>\n",
       "      <td>87.87</td>\n",
       "      <td>87.78</td>\n",
       "      <td>88.09</td>\n",
       "      <td>87.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.50</td>\n",
       "      <td>86.13</td>\n",
       "      <td>86.35</td>\n",
       "      <td>85.99</td>\n",
       "      <td>86.98</td>\n",
       "      <td>86.36</td>\n",
       "      <td>86.79</td>\n",
       "      <td>86.38</td>\n",
       "      <td>86.26</td>\n",
       "      <td>86.39</td>\n",
       "      <td>89.15</td>\n",
       "      <td>88.85</td>\n",
       "      <td>88.85</td>\n",
       "      <td>88.61</td>\n",
       "      <td>88.90</td>\n",
       "      <td>88.89</td>\n",
       "      <td>89.08</td>\n",
       "      <td>88.86</td>\n",
       "      <td>88.77</td>\n",
       "      <td>88.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.36</td>\n",
       "      <td>87.02</td>\n",
       "      <td>87.27</td>\n",
       "      <td>86.90</td>\n",
       "      <td>87.67</td>\n",
       "      <td>87.23</td>\n",
       "      <td>87.82</td>\n",
       "      <td>86.93</td>\n",
       "      <td>87.05</td>\n",
       "      <td>87.21</td>\n",
       "      <td>88.98</td>\n",
       "      <td>89.18</td>\n",
       "      <td>89.03</td>\n",
       "      <td>88.44</td>\n",
       "      <td>88.92</td>\n",
       "      <td>89.40</td>\n",
       "      <td>89.65</td>\n",
       "      <td>89.30</td>\n",
       "      <td>89.22</td>\n",
       "      <td>88.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_acc_run_1  training_acc_run_2  training_acc_run_3  \\\n",
       "0               75.91               74.54               74.28   \n",
       "1               83.51               82.93               83.26   \n",
       "2               85.54               84.93               85.14   \n",
       "3               86.50               86.13               86.35   \n",
       "4               87.36               87.02               87.27   \n",
       "\n",
       "   training_acc_run_4  training_acc_run_5  training_acc_run_6  \\\n",
       "0               74.40               75.65               74.65   \n",
       "1               82.80               83.95               82.68   \n",
       "2               84.75               85.67               85.00   \n",
       "3               85.99               86.98               86.36   \n",
       "4               86.90               87.67               87.23   \n",
       "\n",
       "   training_acc_run_7  training_acc_run_8  training_acc_run_9  \\\n",
       "0               74.97               74.16               74.25   \n",
       "1               83.25               82.69               82.67   \n",
       "2               85.33               84.95               85.00   \n",
       "3               86.79               86.38               86.26   \n",
       "4               87.82               86.93               87.05   \n",
       "\n",
       "   training_acc_run_10  val_acc_run_1  val_acc_run_2  val_acc_run_3  \\\n",
       "0                75.46          84.60          84.48          84.98   \n",
       "1                83.36          87.42          86.47          87.01   \n",
       "2                85.31          88.48          87.74          87.82   \n",
       "3                86.39          89.15          88.85          88.85   \n",
       "4                87.21          88.98          89.18          89.03   \n",
       "\n",
       "   val_acc_run_4  val_acc_run_5  val_acc_run_6  val_acc_run_7  val_acc_run_8  \\\n",
       "0          84.40          85.19          84.87          84.28          83.91   \n",
       "1          86.93          87.71          86.09          86.92          86.36   \n",
       "2          87.58          88.44          88.53          87.87          87.78   \n",
       "3          88.61          88.90          88.89          89.08          88.86   \n",
       "4          88.44          88.92          89.40          89.65          89.30   \n",
       "\n",
       "   val_acc_run_9  val_acc_run_10  \n",
       "0          83.53           84.53  \n",
       "1          86.22           86.72  \n",
       "2          88.09           87.87  \n",
       "3          88.77           88.76  \n",
       "4          89.22           88.93  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_acc = pd.DataFrame(columns=accuracy_cols)\n",
    "\n",
    "for i in range(1,11):\n",
    "    train_val_acc['training_acc_' + 'run_' + str(i)]  = training_history['run_' + str(i)].history['acc'] \n",
    "    train_val_acc['val_acc_'      + 'run_' + str(i)]  = training_history['run_' + str(i)].history['val_acc']\n",
    "train_val_acc = train_val_acc.applymap(lambda x:  x * 100).applymap(lambda x: '%.2f' % x)\n",
    "train_val_acc = train_val_acc.applymap(lambda x: pd.to_numeric(x))\n",
    "train_val_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.35</td>\n",
       "      <td>91.83</td>\n",
       "      <td>92.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.01</td>\n",
       "      <td>92.12</td>\n",
       "      <td>92.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.22</td>\n",
       "      <td>91.64</td>\n",
       "      <td>91.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.89</td>\n",
       "      <td>91.43</td>\n",
       "      <td>91.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93.33</td>\n",
       "      <td>92.13</td>\n",
       "      <td>92.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92.92</td>\n",
       "      <td>91.76</td>\n",
       "      <td>92.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.31</td>\n",
       "      <td>92.04</td>\n",
       "      <td>92.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.19</td>\n",
       "      <td>92.03</td>\n",
       "      <td>92.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93.41</td>\n",
       "      <td>91.77</td>\n",
       "      <td>92.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93.33</td>\n",
       "      <td>91.89</td>\n",
       "      <td>92.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training Accuracy  Validation Accuracy  Testing Accuracy\n",
       "1               93.35                91.83             92.31\n",
       "2               93.01                92.12             92.45\n",
       "3               93.22                91.64             91.77\n",
       "4               92.89                91.43             91.92\n",
       "5               93.33                92.13             92.08\n",
       "6               92.92                91.76             92.26\n",
       "7               93.31                92.04             92.13\n",
       "8               93.19                92.03             92.17\n",
       "9               93.41                91.77             92.36\n",
       "10              93.33                91.89             92.14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_final_acc = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy', 'Testing Accuracy'],index=[i for i in range(1,11)])\n",
    "\n",
    "model_final_acc['Training Accuracy']   = train_val_acc.iloc[49:,:10].T.values\n",
    "model_final_acc['Validation Accuracy'] = train_val_acc.iloc[49:,10:].T.values\n",
    "\n",
    "y_test = []\n",
    "for i in range(1,11):\n",
    "    test = testing_history['acc run_'  + str(i)]\n",
    "    y_test.append(test)\n",
    "model_final_acc['Testing Accuracy']    = y_test\n",
    "model_final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time 21.796345467964805 mints\n"
     ]
    }
   ],
   "source": [
    "t = 0.0\n",
    "for i in range(1,11):\n",
    "    t = t + training_time['run_' + str(i)]\n",
    "avg_time = t/10\n",
    "avg_time = avg_time / 60\n",
    "print('Average time {} mints'.format(avg_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as pyo\n",
    "from   plotly.graph_objs import *\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(a,runs,nb_ephochs):\n",
    "    if (a == 1):\n",
    "        var = 'training_acc_' + 'run_'\n",
    "        avg = train_val_acc.iloc[:,:10].mean(axis=1)\n",
    "        name = 'Average Training Accuracy'\n",
    "        title = 'Taining a Model'\n",
    "    else:\n",
    "        var = 'val_acc_' + 'run_' \n",
    "        avg = train_val_acc.iloc[:,10:].mean(axis=1)\n",
    "        name = 'Average Validation Accuracy'\n",
    "        title = 'Validating a Model'\n",
    "      \n",
    "    \n",
    "    x = [i for i in range(1,nb_ephochs + 1)]\n",
    "    trace = []\n",
    "\n",
    "    for i in range(1,runs):\n",
    "        col = var + str(i)\n",
    "        trace0 = {'type'    : 'scatter',\n",
    "                  'x'       : x,\n",
    "                  'y'       : train_val_acc[col],\n",
    "                  'name'    : col}\n",
    "        trace.append(trace0)\n",
    "    \n",
    "    trace1 = {'type'     : 'scatter',\n",
    "              'x'        : x,\n",
    "              'y'        : avg ,\n",
    "              'name'     : name ,\n",
    "              'mode'     : 'lines+markers',          \n",
    "              'marker'   : {'color' : 'Red',\n",
    "                            'size'  : 10}}\n",
    "    trace.append(trace1)\n",
    "    data = Data(trace)\n",
    "    layout = {'title' :  title,\n",
    "              'xaxis' : {'title' : 'Number of Ephochs'},\n",
    "              'yaxis' : {'title' : 'Accuracy'},\n",
    "              \"width\" : 1200,\n",
    "              \"height\" :600\n",
    "              }\n",
    "    fig = Figure(data = data, layout = layout)\n",
    "\n",
    "    pyo.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "training_acc_run_1",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          75.91,
          83.51,
          85.54,
          86.5,
          87.36,
          87.95,
          88.27,
          88.91,
          89.33,
          89.33,
          89.81,
          89.92,
          90.09,
          90.47,
          90.52,
          90.95,
          90.89,
          91.02,
          91.13,
          91.25,
          91.35,
          91.39,
          91.55,
          91.47,
          91.71,
          91.96,
          92.06,
          92.06,
          92.12,
          92.26,
          92.27,
          92.37,
          92.33,
          92.38,
          92.52,
          92.45,
          92.61,
          92.58,
          92.52,
          92.65,
          92.81,
          92.78,
          92.94,
          92.98,
          92.97,
          93.1,
          93.03,
          92.93,
          93.07,
          93.35
         ]
        },
        {
         "name": "training_acc_run_2",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.54,
          82.93,
          84.93,
          86.13,
          87.02,
          87.44,
          87.94,
          88.62,
          89.05,
          89.33,
          89.56,
          89.76,
          90.01,
          90.21,
          90.19,
          90.48,
          90.59,
          90.81,
          90.85,
          91.13,
          90.98,
          91.36,
          91.32,
          91.55,
          91.48,
          91.67,
          91.76,
          91.72,
          91.84,
          91.91,
          92.15,
          92.09,
          92.34,
          92.35,
          92.34,
          92.31,
          92.59,
          92.61,
          92.45,
          92.55,
          92.58,
          92.67,
          92.67,
          92.91,
          92.62,
          92.9,
          92.74,
          92.94,
          92.89,
          93.01
         ]
        },
        {
         "name": "training_acc_run_3",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.28,
          83.26,
          85.14,
          86.35,
          87.27,
          87.99,
          88.35,
          88.86,
          89.21,
          89.68,
          89.72,
          89.99,
          89.96,
          90.3,
          90.64,
          90.63,
          90.73,
          91.06,
          91,
          91.35,
          91.36,
          91.47,
          91.52,
          91.76,
          91.73,
          91.87,
          91.82,
          92.04,
          92.13,
          92.17,
          92.15,
          92.2,
          92.16,
          92.57,
          92.3,
          92.63,
          92.52,
          92.62,
          92.51,
          92.74,
          92.75,
          92.85,
          92.83,
          92.74,
          92.96,
          93.05,
          92.91,
          93.04,
          93.09,
          93.22
         ]
        },
        {
         "name": "training_acc_run_4",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.4,
          82.8,
          84.75,
          85.99,
          86.9,
          87.54,
          88.15,
          88.39,
          88.84,
          89.04,
          89.21,
          89.38,
          89.88,
          89.97,
          90.03,
          90.37,
          90.42,
          90.66,
          90.63,
          90.77,
          90.99,
          91.15,
          91.23,
          91.12,
          91.47,
          91.4,
          91.7,
          91.68,
          91.74,
          91.73,
          91.9,
          91.85,
          92,
          92.18,
          92.09,
          92.15,
          92.32,
          92.42,
          92.48,
          92.47,
          92.38,
          92.45,
          92.64,
          92.63,
          92.69,
          92.67,
          92.79,
          92.75,
          92.91,
          92.89
         ]
        },
        {
         "name": "training_acc_run_5",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          75.65,
          83.95,
          85.67,
          86.98,
          87.67,
          88.31,
          88.81,
          89.16,
          89.37,
          89.62,
          90.02,
          90.15,
          90.37,
          90.6,
          90.84,
          90.93,
          91.13,
          91.26,
          91.31,
          91.41,
          91.54,
          91.38,
          91.76,
          91.7,
          91.99,
          92.12,
          92.07,
          92.09,
          92.04,
          92.34,
          92.48,
          92.51,
          92.58,
          92.56,
          92.59,
          92.82,
          92.72,
          92.76,
          92.82,
          92.82,
          92.84,
          92.94,
          92.86,
          93.04,
          93.09,
          93.02,
          93.19,
          93.3,
          93.18,
          93.33
         ]
        },
        {
         "name": "training_acc_run_6",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.65,
          82.68,
          85,
          86.36,
          87.23,
          87.68,
          88.39,
          88.69,
          89.12,
          89.37,
          89.54,
          89.83,
          90.17,
          90.06,
          90.49,
          90.58,
          90.9,
          90.96,
          91.07,
          91.13,
          91.09,
          91.44,
          91.38,
          91.62,
          91.67,
          91.79,
          91.91,
          91.95,
          91.97,
          92.13,
          92.2,
          92.42,
          92.26,
          92.21,
          92.14,
          92.52,
          92.53,
          92.5,
          92.75,
          92.84,
          92.79,
          92.88,
          92.94,
          92.67,
          93.07,
          92.87,
          92.92,
          92.8,
          93.07,
          92.92
         ]
        },
        {
         "name": "training_acc_run_7",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.97,
          83.25,
          85.33,
          86.79,
          87.82,
          88.22,
          88.66,
          89.12,
          89.63,
          89.77,
          89.91,
          90.3,
          90.22,
          90.56,
          90.64,
          91,
          90.95,
          91.12,
          91.35,
          91.3,
          91.56,
          91.73,
          91.88,
          91.91,
          91.95,
          92.02,
          92.11,
          92.12,
          92.2,
          92.33,
          92.4,
          92.43,
          92.48,
          92.61,
          92.62,
          92.56,
          92.83,
          92.84,
          92.9,
          92.87,
          93.01,
          92.9,
          93,
          93,
          93.07,
          93.01,
          93.23,
          93.14,
          93.29,
          93.31
         ]
        },
        {
         "name": "training_acc_run_8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.16,
          82.69,
          84.95,
          86.38,
          86.93,
          87.69,
          88.56,
          88.79,
          88.91,
          89.51,
          89.83,
          89.88,
          90,
          90.33,
          90.34,
          90.71,
          90.87,
          90.96,
          90.98,
          91.2,
          91.42,
          91.42,
          91.62,
          91.61,
          91.81,
          91.72,
          91.86,
          92.12,
          92,
          92.01,
          92.29,
          92.2,
          92.19,
          92.41,
          92.48,
          92.46,
          92.51,
          92.57,
          92.8,
          92.91,
          92.67,
          92.7,
          92.91,
          92.97,
          92.97,
          93,
          93,
          93.13,
          93.31,
          93.19
         ]
        },
        {
         "name": "training_acc_run_9",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.25,
          82.67,
          85,
          86.26,
          87.05,
          87.66,
          88.39,
          88.66,
          89.03,
          89.34,
          89.48,
          89.78,
          90.15,
          90.44,
          90.34,
          90.71,
          90.67,
          91,
          91.08,
          91.33,
          91.36,
          91.4,
          91.44,
          91.48,
          91.87,
          91.62,
          91.89,
          92.12,
          92.16,
          92,
          92.09,
          92.44,
          92.34,
          92.3,
          92.46,
          92.69,
          92.51,
          92.58,
          92.46,
          92.68,
          92.58,
          92.68,
          92.89,
          92.67,
          92.98,
          92.91,
          92.91,
          92.99,
          93.05,
          93.41
         ]
        },
        {
         "name": "training_acc_run_10",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          75.46,
          83.36,
          85.31,
          86.39,
          87.21,
          87.77,
          88.25,
          88.82,
          89.2,
          89.52,
          89.82,
          89.95,
          90.17,
          90.49,
          90.61,
          90.73,
          90.87,
          91,
          91.23,
          91.22,
          91.31,
          91.46,
          91.51,
          91.69,
          91.74,
          91.96,
          91.94,
          91.99,
          92.25,
          92.21,
          92.17,
          92.38,
          92.37,
          92.41,
          92.53,
          92.49,
          92.69,
          92.61,
          92.75,
          92.78,
          92.82,
          92.65,
          93,
          92.81,
          93.1,
          93.14,
          93.2,
          93.13,
          93.02,
          93.33
         ]
        },
        {
         "marker": {
          "color": "Red",
          "size": 10
         },
         "mode": "lines+markers",
         "name": "Average Training Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          74.827,
          83.10999999999999,
          85.162,
          86.413,
          87.24600000000001,
          87.82500000000002,
          88.37699999999998,
          88.80199999999998,
          89.169,
          89.45100000000001,
          89.69000000000001,
          89.894,
          90.102,
          90.343,
          90.46400000000001,
          90.70900000000002,
          90.802,
          90.985,
          91.06300000000002,
          91.209,
          91.296,
          91.42,
          91.521,
          91.59100000000001,
          91.74199999999999,
          91.813,
          91.91199999999999,
          91.989,
          92.045,
          92.10900000000001,
          92.21000000000001,
          92.289,
          92.30500000000002,
          92.398,
          92.40700000000001,
          92.50800000000001,
          92.583,
          92.60900000000001,
          92.64399999999999,
          92.731,
          92.723,
          92.74999999999999,
          92.868,
          92.84200000000001,
          92.95200000000001,
          92.967,
          92.99199999999999,
          93.015,
          93.088,
          93.196
         ]
        }
       ],
       "layout": {
        "height": 600,
        "title": "Taining a Model",
        "width": 1200,
        "xaxis": {
         "title": "Number of Ephochs"
        },
        "yaxis": {
         "title": "Accuracy"
        }
       }
      },
      "text/html": [
       "<div id=\"ca7d0ab3-c0b2-4325-9735-06056d01a020\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ca7d0ab3-c0b2-4325-9735-06056d01a020\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.91, 83.51, 85.54, 86.5, 87.36, 87.95, 88.27, 88.91, 89.33, 89.33, 89.81, 89.92, 90.09, 90.47, 90.52, 90.95, 90.89, 91.02, 91.13, 91.25, 91.35, 91.39, 91.55, 91.47, 91.71, 91.96, 92.06, 92.06, 92.12, 92.26, 92.27, 92.37, 92.33, 92.38, 92.52, 92.45, 92.61, 92.58, 92.52, 92.65, 92.81, 92.78, 92.94, 92.98, 92.97, 93.1, 93.03, 92.93, 93.07, 93.35], \"name\": \"training_acc_run_1\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.54, 82.93, 84.93, 86.13, 87.02, 87.44, 87.94, 88.62, 89.05, 89.33, 89.56, 89.76, 90.01, 90.21, 90.19, 90.48, 90.59, 90.81, 90.85, 91.13, 90.98, 91.36, 91.32, 91.55, 91.48, 91.67, 91.76, 91.72, 91.84, 91.91, 92.15, 92.09, 92.34, 92.35, 92.34, 92.31, 92.59, 92.61, 92.45, 92.55, 92.58, 92.67, 92.67, 92.91, 92.62, 92.9, 92.74, 92.94, 92.89, 93.01], \"name\": \"training_acc_run_2\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.28, 83.26, 85.14, 86.35, 87.27, 87.99, 88.35, 88.86, 89.21, 89.68, 89.72, 89.99, 89.96, 90.3, 90.64, 90.63, 90.73, 91.06, 91.0, 91.35, 91.36, 91.47, 91.52, 91.76, 91.73, 91.87, 91.82, 92.04, 92.13, 92.17, 92.15, 92.2, 92.16, 92.57, 92.3, 92.63, 92.52, 92.62, 92.51, 92.74, 92.75, 92.85, 92.83, 92.74, 92.96, 93.05, 92.91, 93.04, 93.09, 93.22], \"name\": \"training_acc_run_3\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.4, 82.8, 84.75, 85.99, 86.9, 87.54, 88.15, 88.39, 88.84, 89.04, 89.21, 89.38, 89.88, 89.97, 90.03, 90.37, 90.42, 90.66, 90.63, 90.77, 90.99, 91.15, 91.23, 91.12, 91.47, 91.4, 91.7, 91.68, 91.74, 91.73, 91.9, 91.85, 92.0, 92.18, 92.09, 92.15, 92.32, 92.42, 92.48, 92.47, 92.38, 92.45, 92.64, 92.63, 92.69, 92.67, 92.79, 92.75, 92.91, 92.89], \"name\": \"training_acc_run_4\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.65, 83.95, 85.67, 86.98, 87.67, 88.31, 88.81, 89.16, 89.37, 89.62, 90.02, 90.15, 90.37, 90.6, 90.84, 90.93, 91.13, 91.26, 91.31, 91.41, 91.54, 91.38, 91.76, 91.7, 91.99, 92.12, 92.07, 92.09, 92.04, 92.34, 92.48, 92.51, 92.58, 92.56, 92.59, 92.82, 92.72, 92.76, 92.82, 92.82, 92.84, 92.94, 92.86, 93.04, 93.09, 93.02, 93.19, 93.3, 93.18, 93.33], \"name\": \"training_acc_run_5\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.65, 82.68, 85.0, 86.36, 87.23, 87.68, 88.39, 88.69, 89.12, 89.37, 89.54, 89.83, 90.17, 90.06, 90.49, 90.58, 90.9, 90.96, 91.07, 91.13, 91.09, 91.44, 91.38, 91.62, 91.67, 91.79, 91.91, 91.95, 91.97, 92.13, 92.2, 92.42, 92.26, 92.21, 92.14, 92.52, 92.53, 92.5, 92.75, 92.84, 92.79, 92.88, 92.94, 92.67, 93.07, 92.87, 92.92, 92.8, 93.07, 92.92], \"name\": \"training_acc_run_6\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.97, 83.25, 85.33, 86.79, 87.82, 88.22, 88.66, 89.12, 89.63, 89.77, 89.91, 90.3, 90.22, 90.56, 90.64, 91.0, 90.95, 91.12, 91.35, 91.3, 91.56, 91.73, 91.88, 91.91, 91.95, 92.02, 92.11, 92.12, 92.2, 92.33, 92.4, 92.43, 92.48, 92.61, 92.62, 92.56, 92.83, 92.84, 92.9, 92.87, 93.01, 92.9, 93.0, 93.0, 93.07, 93.01, 93.23, 93.14, 93.29, 93.31], \"name\": \"training_acc_run_7\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.16, 82.69, 84.95, 86.38, 86.93, 87.69, 88.56, 88.79, 88.91, 89.51, 89.83, 89.88, 90.0, 90.33, 90.34, 90.71, 90.87, 90.96, 90.98, 91.2, 91.42, 91.42, 91.62, 91.61, 91.81, 91.72, 91.86, 92.12, 92.0, 92.01, 92.29, 92.2, 92.19, 92.41, 92.48, 92.46, 92.51, 92.57, 92.8, 92.91, 92.67, 92.7, 92.91, 92.97, 92.97, 93.0, 93.0, 93.13, 93.31, 93.19], \"name\": \"training_acc_run_8\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.25, 82.67, 85.0, 86.26, 87.05, 87.66, 88.39, 88.66, 89.03, 89.34, 89.48, 89.78, 90.15, 90.44, 90.34, 90.71, 90.67, 91.0, 91.08, 91.33, 91.36, 91.4, 91.44, 91.48, 91.87, 91.62, 91.89, 92.12, 92.16, 92.0, 92.09, 92.44, 92.34, 92.3, 92.46, 92.69, 92.51, 92.58, 92.46, 92.68, 92.58, 92.68, 92.89, 92.67, 92.98, 92.91, 92.91, 92.99, 93.05, 93.41], \"name\": \"training_acc_run_9\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.46, 83.36, 85.31, 86.39, 87.21, 87.77, 88.25, 88.82, 89.2, 89.52, 89.82, 89.95, 90.17, 90.49, 90.61, 90.73, 90.87, 91.0, 91.23, 91.22, 91.31, 91.46, 91.51, 91.69, 91.74, 91.96, 91.94, 91.99, 92.25, 92.21, 92.17, 92.38, 92.37, 92.41, 92.53, 92.49, 92.69, 92.61, 92.75, 92.78, 92.82, 92.65, 93.0, 92.81, 93.1, 93.14, 93.2, 93.13, 93.02, 93.33], \"name\": \"training_acc_run_10\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.827, 83.10999999999999, 85.162, 86.413, 87.24600000000001, 87.82500000000002, 88.37699999999998, 88.80199999999998, 89.169, 89.45100000000001, 89.69000000000001, 89.894, 90.102, 90.343, 90.46400000000001, 90.70900000000002, 90.802, 90.985, 91.06300000000002, 91.209, 91.296, 91.42, 91.521, 91.59100000000001, 91.74199999999999, 91.813, 91.91199999999999, 91.989, 92.045, 92.10900000000001, 92.21000000000001, 92.289, 92.30500000000002, 92.398, 92.40700000000001, 92.50800000000001, 92.583, 92.60900000000001, 92.64399999999999, 92.731, 92.723, 92.74999999999999, 92.868, 92.84200000000001, 92.95200000000001, 92.967, 92.99199999999999, 93.015, 93.088, 93.196], \"name\": \"Average Training Accuracy\", \"mode\": \"lines+markers\", \"marker\": {\"color\": \"Red\", \"size\": 10}}], {\"title\": \"Taining a Model\", \"xaxis\": {\"title\": \"Number of Ephochs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ca7d0ab3-c0b2-4325-9735-06056d01a020\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ca7d0ab3-c0b2-4325-9735-06056d01a020\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.91, 83.51, 85.54, 86.5, 87.36, 87.95, 88.27, 88.91, 89.33, 89.33, 89.81, 89.92, 90.09, 90.47, 90.52, 90.95, 90.89, 91.02, 91.13, 91.25, 91.35, 91.39, 91.55, 91.47, 91.71, 91.96, 92.06, 92.06, 92.12, 92.26, 92.27, 92.37, 92.33, 92.38, 92.52, 92.45, 92.61, 92.58, 92.52, 92.65, 92.81, 92.78, 92.94, 92.98, 92.97, 93.1, 93.03, 92.93, 93.07, 93.35], \"name\": \"training_acc_run_1\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.54, 82.93, 84.93, 86.13, 87.02, 87.44, 87.94, 88.62, 89.05, 89.33, 89.56, 89.76, 90.01, 90.21, 90.19, 90.48, 90.59, 90.81, 90.85, 91.13, 90.98, 91.36, 91.32, 91.55, 91.48, 91.67, 91.76, 91.72, 91.84, 91.91, 92.15, 92.09, 92.34, 92.35, 92.34, 92.31, 92.59, 92.61, 92.45, 92.55, 92.58, 92.67, 92.67, 92.91, 92.62, 92.9, 92.74, 92.94, 92.89, 93.01], \"name\": \"training_acc_run_2\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.28, 83.26, 85.14, 86.35, 87.27, 87.99, 88.35, 88.86, 89.21, 89.68, 89.72, 89.99, 89.96, 90.3, 90.64, 90.63, 90.73, 91.06, 91.0, 91.35, 91.36, 91.47, 91.52, 91.76, 91.73, 91.87, 91.82, 92.04, 92.13, 92.17, 92.15, 92.2, 92.16, 92.57, 92.3, 92.63, 92.52, 92.62, 92.51, 92.74, 92.75, 92.85, 92.83, 92.74, 92.96, 93.05, 92.91, 93.04, 93.09, 93.22], \"name\": \"training_acc_run_3\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.4, 82.8, 84.75, 85.99, 86.9, 87.54, 88.15, 88.39, 88.84, 89.04, 89.21, 89.38, 89.88, 89.97, 90.03, 90.37, 90.42, 90.66, 90.63, 90.77, 90.99, 91.15, 91.23, 91.12, 91.47, 91.4, 91.7, 91.68, 91.74, 91.73, 91.9, 91.85, 92.0, 92.18, 92.09, 92.15, 92.32, 92.42, 92.48, 92.47, 92.38, 92.45, 92.64, 92.63, 92.69, 92.67, 92.79, 92.75, 92.91, 92.89], \"name\": \"training_acc_run_4\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.65, 83.95, 85.67, 86.98, 87.67, 88.31, 88.81, 89.16, 89.37, 89.62, 90.02, 90.15, 90.37, 90.6, 90.84, 90.93, 91.13, 91.26, 91.31, 91.41, 91.54, 91.38, 91.76, 91.7, 91.99, 92.12, 92.07, 92.09, 92.04, 92.34, 92.48, 92.51, 92.58, 92.56, 92.59, 92.82, 92.72, 92.76, 92.82, 92.82, 92.84, 92.94, 92.86, 93.04, 93.09, 93.02, 93.19, 93.3, 93.18, 93.33], \"name\": \"training_acc_run_5\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.65, 82.68, 85.0, 86.36, 87.23, 87.68, 88.39, 88.69, 89.12, 89.37, 89.54, 89.83, 90.17, 90.06, 90.49, 90.58, 90.9, 90.96, 91.07, 91.13, 91.09, 91.44, 91.38, 91.62, 91.67, 91.79, 91.91, 91.95, 91.97, 92.13, 92.2, 92.42, 92.26, 92.21, 92.14, 92.52, 92.53, 92.5, 92.75, 92.84, 92.79, 92.88, 92.94, 92.67, 93.07, 92.87, 92.92, 92.8, 93.07, 92.92], \"name\": \"training_acc_run_6\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.97, 83.25, 85.33, 86.79, 87.82, 88.22, 88.66, 89.12, 89.63, 89.77, 89.91, 90.3, 90.22, 90.56, 90.64, 91.0, 90.95, 91.12, 91.35, 91.3, 91.56, 91.73, 91.88, 91.91, 91.95, 92.02, 92.11, 92.12, 92.2, 92.33, 92.4, 92.43, 92.48, 92.61, 92.62, 92.56, 92.83, 92.84, 92.9, 92.87, 93.01, 92.9, 93.0, 93.0, 93.07, 93.01, 93.23, 93.14, 93.29, 93.31], \"name\": \"training_acc_run_7\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.16, 82.69, 84.95, 86.38, 86.93, 87.69, 88.56, 88.79, 88.91, 89.51, 89.83, 89.88, 90.0, 90.33, 90.34, 90.71, 90.87, 90.96, 90.98, 91.2, 91.42, 91.42, 91.62, 91.61, 91.81, 91.72, 91.86, 92.12, 92.0, 92.01, 92.29, 92.2, 92.19, 92.41, 92.48, 92.46, 92.51, 92.57, 92.8, 92.91, 92.67, 92.7, 92.91, 92.97, 92.97, 93.0, 93.0, 93.13, 93.31, 93.19], \"name\": \"training_acc_run_8\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.25, 82.67, 85.0, 86.26, 87.05, 87.66, 88.39, 88.66, 89.03, 89.34, 89.48, 89.78, 90.15, 90.44, 90.34, 90.71, 90.67, 91.0, 91.08, 91.33, 91.36, 91.4, 91.44, 91.48, 91.87, 91.62, 91.89, 92.12, 92.16, 92.0, 92.09, 92.44, 92.34, 92.3, 92.46, 92.69, 92.51, 92.58, 92.46, 92.68, 92.58, 92.68, 92.89, 92.67, 92.98, 92.91, 92.91, 92.99, 93.05, 93.41], \"name\": \"training_acc_run_9\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [75.46, 83.36, 85.31, 86.39, 87.21, 87.77, 88.25, 88.82, 89.2, 89.52, 89.82, 89.95, 90.17, 90.49, 90.61, 90.73, 90.87, 91.0, 91.23, 91.22, 91.31, 91.46, 91.51, 91.69, 91.74, 91.96, 91.94, 91.99, 92.25, 92.21, 92.17, 92.38, 92.37, 92.41, 92.53, 92.49, 92.69, 92.61, 92.75, 92.78, 92.82, 92.65, 93.0, 92.81, 93.1, 93.14, 93.2, 93.13, 93.02, 93.33], \"name\": \"training_acc_run_10\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [74.827, 83.10999999999999, 85.162, 86.413, 87.24600000000001, 87.82500000000002, 88.37699999999998, 88.80199999999998, 89.169, 89.45100000000001, 89.69000000000001, 89.894, 90.102, 90.343, 90.46400000000001, 90.70900000000002, 90.802, 90.985, 91.06300000000002, 91.209, 91.296, 91.42, 91.521, 91.59100000000001, 91.74199999999999, 91.813, 91.91199999999999, 91.989, 92.045, 92.10900000000001, 92.21000000000001, 92.289, 92.30500000000002, 92.398, 92.40700000000001, 92.50800000000001, 92.583, 92.60900000000001, 92.64399999999999, 92.731, 92.723, 92.74999999999999, 92.868, 92.84200000000001, 92.95200000000001, 92.967, 92.99199999999999, 93.015, 93.088, 93.196], \"name\": \"Average Training Accuracy\", \"mode\": \"lines+markers\", \"marker\": {\"color\": \"Red\", \"size\": 10}}], {\"title\": \"Taining a Model\", \"xaxis\": {\"title\": \"Number of Ephochs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "val_acc_run_1",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.6,
          87.42,
          88.48,
          89.15,
          88.98,
          89.12,
          89.66,
          90.05,
          90.26,
          90.81,
          90.48,
          90.66,
          90.72,
          91.17,
          91.2,
          90.97,
          90.86,
          91.28,
          91.48,
          91.42,
          91.57,
          91.08,
          91.31,
          90.99,
          91.67,
          91.1,
          91.43,
          91.65,
          91.62,
          91.45,
          90.68,
          91.27,
          91.59,
          91.83,
          91.55,
          91.68,
          91.53,
          91.75,
          91.86,
          91.64,
          91.49,
          91.59,
          91.39,
          91.66,
          91.66,
          91.36,
          91.72,
          91.64,
          91.78,
          91.83
         ]
        },
        {
         "name": "val_acc_run_2",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.48,
          86.47,
          87.74,
          88.85,
          89.18,
          89.91,
          89.81,
          90.32,
          89.61,
          90.53,
          90.57,
          90.72,
          89.68,
          90.97,
          90.74,
          90.97,
          90.95,
          91.31,
          90.56,
          91.5,
          91.22,
          91.56,
          91.29,
          91.52,
          91.38,
          91.67,
          91.47,
          91.57,
          91.61,
          91.89,
          91.41,
          91.65,
          91.74,
          91.59,
          91.68,
          91.91,
          91.85,
          91.46,
          91.67,
          91.57,
          91.72,
          92.03,
          91.88,
          91.81,
          91.78,
          91.45,
          91.83,
          91.48,
          91.79,
          92.12
         ]
        },
        {
         "name": "val_acc_run_3",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.98,
          87.01,
          87.82,
          88.85,
          89.03,
          90.1,
          89.98,
          90.12,
          90.42,
          90.47,
          90.44,
          90.75,
          90.85,
          90.97,
          91.5,
          91.56,
          91.54,
          90.87,
          91.59,
          91.91,
          91.83,
          91.84,
          91.47,
          91.78,
          91.56,
          91.67,
          91.08,
          91.55,
          91.96,
          91.97,
          91.47,
          91.91,
          91.75,
          91.72,
          92.09,
          91.71,
          91.69,
          91.91,
          91.55,
          91.8,
          92.05,
          92,
          91.67,
          91.69,
          91.76,
          92.06,
          91.79,
          92.12,
          91.92,
          91.64
         ]
        },
        {
         "name": "val_acc_run_4",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.4,
          86.93,
          87.58,
          88.61,
          88.44,
          89.29,
          89.44,
          89.31,
          90.38,
          90.26,
          90.78,
          90.54,
          90.65,
          90.98,
          90.77,
          90.93,
          91.22,
          90.71,
          91.29,
          90.37,
          91.51,
          91.37,
          91.56,
          91.55,
          91.58,
          91.47,
          91.44,
          91.61,
          91.51,
          91.66,
          91.17,
          91.83,
          91.51,
          91.62,
          91.76,
          91.46,
          91.5,
          91.83,
          91.43,
          91.9,
          91.8,
          91.71,
          91.87,
          91.79,
          91.89,
          91.98,
          91.83,
          91.57,
          91.72,
          91.43
         ]
        },
        {
         "name": "val_acc_run_5",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          85.19,
          87.71,
          88.44,
          88.9,
          88.92,
          90.13,
          90.29,
          90.5,
          90.36,
          90.66,
          90.73,
          90.76,
          91.03,
          91.27,
          91.56,
          91.12,
          91.36,
          91.37,
          91.36,
          91.43,
          91.64,
          91.72,
          91.61,
          91.74,
          91.83,
          91.33,
          91.51,
          91.85,
          91.95,
          91.32,
          91.97,
          91.9,
          91.62,
          91.92,
          91.39,
          91.58,
          91.8,
          91.86,
          91.96,
          91.38,
          92.13,
          92.22,
          92.23,
          91.98,
          92.12,
          91.97,
          91.5,
          92.12,
          92,
          92.13
         ]
        },
        {
         "name": "val_acc_run_6",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.87,
          86.09,
          88.53,
          88.89,
          89.4,
          89.65,
          89.88,
          89.79,
          90.66,
          89.96,
          91.03,
          91.22,
          89.75,
          91.25,
          91.2,
          91.19,
          91.6,
          91.66,
          91.26,
          91.17,
          91.51,
          91.45,
          91.42,
          91.58,
          91.56,
          91.92,
          91.63,
          91.37,
          91.3,
          91.78,
          91.71,
          91.55,
          91.67,
          91.53,
          91.8,
          91.89,
          91.88,
          91.83,
          91.91,
          92.03,
          92.09,
          91.61,
          91.81,
          91.61,
          91.51,
          91.68,
          91.6,
          92.03,
          91.75,
          91.76
         ]
        },
        {
         "name": "val_acc_run_7",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.28,
          86.92,
          87.87,
          89.08,
          89.65,
          89.5,
          89.94,
          89.97,
          90.33,
          90.92,
          90.92,
          90.9,
          91.01,
          90.13,
          91.2,
          91.65,
          91.54,
          91.13,
          91.84,
          91.69,
          91.55,
          91.57,
          91.35,
          91.72,
          92,
          91.6,
          91.81,
          92.05,
          92.03,
          91.88,
          92,
          92.03,
          91.22,
          91.9,
          91.47,
          92.13,
          92.15,
          91.91,
          92.18,
          91.78,
          92.11,
          92.26,
          91.97,
          91.8,
          92.13,
          92.06,
          91.88,
          92.02,
          91.59,
          92.04
         ]
        },
        {
         "name": "val_acc_run_8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          83.91,
          86.36,
          87.78,
          88.86,
          89.3,
          89.82,
          89.8,
          90.13,
          90.23,
          90.62,
          90.88,
          91.03,
          90.77,
          91.06,
          91.03,
          91.01,
          91.47,
          91.21,
          91.56,
          91.67,
          91.36,
          91.53,
          91.87,
          91.62,
          91.39,
          91.5,
          91.73,
          91.97,
          92.07,
          92.03,
          91.47,
          91.87,
          92.03,
          91.85,
          92,
          91.77,
          91.87,
          92.09,
          91.83,
          91.83,
          91.82,
          92.02,
          91.87,
          92.2,
          92.01,
          91.72,
          91.88,
          91.82,
          92.12,
          92.03
         ]
        },
        {
         "name": "val_acc_run_9",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          83.53,
          86.22,
          88.09,
          88.77,
          89.22,
          89.38,
          89.48,
          89.82,
          90.33,
          90.75,
          90.8,
          90.55,
          91.09,
          90.92,
          90.92,
          90.83,
          90.81,
          91.43,
          91.36,
          91.68,
          91.64,
          91.43,
          91.84,
          91.54,
          91.6,
          91.61,
          91.62,
          90.97,
          91.77,
          91.45,
          91.51,
          91.92,
          91.88,
          91.6,
          91.84,
          91.7,
          91.66,
          91.77,
          92.04,
          91.95,
          91.51,
          92.04,
          91.14,
          91.77,
          91.66,
          91.92,
          91.92,
          92.12,
          91.77,
          91.77
         ]
        },
        {
         "name": "val_acc_run_10",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.53,
          86.72,
          87.87,
          88.76,
          88.93,
          89.85,
          90.06,
          90.08,
          90.53,
          90.63,
          90.42,
          90.83,
          90.89,
          90.79,
          91.1,
          91.38,
          91.2,
          91.27,
          91.47,
          91.43,
          91.2,
          91.67,
          91.45,
          91.51,
          91.61,
          91.47,
          91.52,
          91.46,
          91.55,
          91.73,
          91.64,
          91.93,
          91.72,
          91.51,
          91.57,
          91.87,
          91.76,
          91.74,
          91.94,
          91.72,
          91.72,
          91.87,
          91.88,
          91.69,
          91.55,
          91.61,
          91.96,
          91.75,
          91.78,
          91.89
         ]
        },
        {
         "marker": {
          "color": "Red",
          "size": 10
         },
         "mode": "lines+markers",
         "name": "Average Validation Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50
         ],
         "y": [
          84.477,
          86.785,
          88.02,
          88.872,
          89.10499999999999,
          89.675,
          89.83399999999999,
          90.009,
          90.311,
          90.561,
          90.70499999999998,
          90.79599999999999,
          90.64399999999999,
          90.951,
          91.122,
          91.161,
          91.25500000000002,
          91.224,
          91.37700000000001,
          91.42699999999999,
          91.503,
          91.52200000000002,
          91.51700000000002,
          91.55499999999999,
          91.618,
          91.534,
          91.52399999999999,
          91.605,
          91.737,
          91.71600000000001,
          91.50300000000001,
          91.78599999999999,
          91.673,
          91.70700000000001,
          91.715,
          91.77000000000001,
          91.76899999999999,
          91.815,
          91.83699999999999,
          91.76,
          91.84400000000001,
          91.93499999999999,
          91.771,
          91.8,
          91.80699999999999,
          91.78099999999999,
          91.791,
          91.86699999999999,
          91.822,
          91.86399999999999
         ]
        }
       ],
       "layout": {
        "height": 600,
        "title": "Validating a Model",
        "width": 1200,
        "xaxis": {
         "title": "Number of Ephochs"
        },
        "yaxis": {
         "title": "Accuracy"
        }
       }
      },
      "text/html": [
       "<div id=\"11754037-97e5-4cd4-ba29-f18727b856d7\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"11754037-97e5-4cd4-ba29-f18727b856d7\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.6, 87.42, 88.48, 89.15, 88.98, 89.12, 89.66, 90.05, 90.26, 90.81, 90.48, 90.66, 90.72, 91.17, 91.2, 90.97, 90.86, 91.28, 91.48, 91.42, 91.57, 91.08, 91.31, 90.99, 91.67, 91.1, 91.43, 91.65, 91.62, 91.45, 90.68, 91.27, 91.59, 91.83, 91.55, 91.68, 91.53, 91.75, 91.86, 91.64, 91.49, 91.59, 91.39, 91.66, 91.66, 91.36, 91.72, 91.64, 91.78, 91.83], \"name\": \"val_acc_run_1\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.48, 86.47, 87.74, 88.85, 89.18, 89.91, 89.81, 90.32, 89.61, 90.53, 90.57, 90.72, 89.68, 90.97, 90.74, 90.97, 90.95, 91.31, 90.56, 91.5, 91.22, 91.56, 91.29, 91.52, 91.38, 91.67, 91.47, 91.57, 91.61, 91.89, 91.41, 91.65, 91.74, 91.59, 91.68, 91.91, 91.85, 91.46, 91.67, 91.57, 91.72, 92.03, 91.88, 91.81, 91.78, 91.45, 91.83, 91.48, 91.79, 92.12], \"name\": \"val_acc_run_2\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.98, 87.01, 87.82, 88.85, 89.03, 90.1, 89.98, 90.12, 90.42, 90.47, 90.44, 90.75, 90.85, 90.97, 91.5, 91.56, 91.54, 90.87, 91.59, 91.91, 91.83, 91.84, 91.47, 91.78, 91.56, 91.67, 91.08, 91.55, 91.96, 91.97, 91.47, 91.91, 91.75, 91.72, 92.09, 91.71, 91.69, 91.91, 91.55, 91.8, 92.05, 92.0, 91.67, 91.69, 91.76, 92.06, 91.79, 92.12, 91.92, 91.64], \"name\": \"val_acc_run_3\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.4, 86.93, 87.58, 88.61, 88.44, 89.29, 89.44, 89.31, 90.38, 90.26, 90.78, 90.54, 90.65, 90.98, 90.77, 90.93, 91.22, 90.71, 91.29, 90.37, 91.51, 91.37, 91.56, 91.55, 91.58, 91.47, 91.44, 91.61, 91.51, 91.66, 91.17, 91.83, 91.51, 91.62, 91.76, 91.46, 91.5, 91.83, 91.43, 91.9, 91.8, 91.71, 91.87, 91.79, 91.89, 91.98, 91.83, 91.57, 91.72, 91.43], \"name\": \"val_acc_run_4\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [85.19, 87.71, 88.44, 88.9, 88.92, 90.13, 90.29, 90.5, 90.36, 90.66, 90.73, 90.76, 91.03, 91.27, 91.56, 91.12, 91.36, 91.37, 91.36, 91.43, 91.64, 91.72, 91.61, 91.74, 91.83, 91.33, 91.51, 91.85, 91.95, 91.32, 91.97, 91.9, 91.62, 91.92, 91.39, 91.58, 91.8, 91.86, 91.96, 91.38, 92.13, 92.22, 92.23, 91.98, 92.12, 91.97, 91.5, 92.12, 92.0, 92.13], \"name\": \"val_acc_run_5\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.87, 86.09, 88.53, 88.89, 89.4, 89.65, 89.88, 89.79, 90.66, 89.96, 91.03, 91.22, 89.75, 91.25, 91.2, 91.19, 91.6, 91.66, 91.26, 91.17, 91.51, 91.45, 91.42, 91.58, 91.56, 91.92, 91.63, 91.37, 91.3, 91.78, 91.71, 91.55, 91.67, 91.53, 91.8, 91.89, 91.88, 91.83, 91.91, 92.03, 92.09, 91.61, 91.81, 91.61, 91.51, 91.68, 91.6, 92.03, 91.75, 91.76], \"name\": \"val_acc_run_6\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.28, 86.92, 87.87, 89.08, 89.65, 89.5, 89.94, 89.97, 90.33, 90.92, 90.92, 90.9, 91.01, 90.13, 91.2, 91.65, 91.54, 91.13, 91.84, 91.69, 91.55, 91.57, 91.35, 91.72, 92.0, 91.6, 91.81, 92.05, 92.03, 91.88, 92.0, 92.03, 91.22, 91.9, 91.47, 92.13, 92.15, 91.91, 92.18, 91.78, 92.11, 92.26, 91.97, 91.8, 92.13, 92.06, 91.88, 92.02, 91.59, 92.04], \"name\": \"val_acc_run_7\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [83.91, 86.36, 87.78, 88.86, 89.3, 89.82, 89.8, 90.13, 90.23, 90.62, 90.88, 91.03, 90.77, 91.06, 91.03, 91.01, 91.47, 91.21, 91.56, 91.67, 91.36, 91.53, 91.87, 91.62, 91.39, 91.5, 91.73, 91.97, 92.07, 92.03, 91.47, 91.87, 92.03, 91.85, 92.0, 91.77, 91.87, 92.09, 91.83, 91.83, 91.82, 92.02, 91.87, 92.2, 92.01, 91.72, 91.88, 91.82, 92.12, 92.03], \"name\": \"val_acc_run_8\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [83.53, 86.22, 88.09, 88.77, 89.22, 89.38, 89.48, 89.82, 90.33, 90.75, 90.8, 90.55, 91.09, 90.92, 90.92, 90.83, 90.81, 91.43, 91.36, 91.68, 91.64, 91.43, 91.84, 91.54, 91.6, 91.61, 91.62, 90.97, 91.77, 91.45, 91.51, 91.92, 91.88, 91.6, 91.84, 91.7, 91.66, 91.77, 92.04, 91.95, 91.51, 92.04, 91.14, 91.77, 91.66, 91.92, 91.92, 92.12, 91.77, 91.77], \"name\": \"val_acc_run_9\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.53, 86.72, 87.87, 88.76, 88.93, 89.85, 90.06, 90.08, 90.53, 90.63, 90.42, 90.83, 90.89, 90.79, 91.1, 91.38, 91.2, 91.27, 91.47, 91.43, 91.2, 91.67, 91.45, 91.51, 91.61, 91.47, 91.52, 91.46, 91.55, 91.73, 91.64, 91.93, 91.72, 91.51, 91.57, 91.87, 91.76, 91.74, 91.94, 91.72, 91.72, 91.87, 91.88, 91.69, 91.55, 91.61, 91.96, 91.75, 91.78, 91.89], \"name\": \"val_acc_run_10\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.477, 86.785, 88.02, 88.872, 89.10499999999999, 89.675, 89.83399999999999, 90.009, 90.311, 90.561, 90.70499999999998, 90.79599999999999, 90.64399999999999, 90.951, 91.122, 91.161, 91.25500000000002, 91.224, 91.37700000000001, 91.42699999999999, 91.503, 91.52200000000002, 91.51700000000002, 91.55499999999999, 91.618, 91.534, 91.52399999999999, 91.605, 91.737, 91.71600000000001, 91.50300000000001, 91.78599999999999, 91.673, 91.70700000000001, 91.715, 91.77000000000001, 91.76899999999999, 91.815, 91.83699999999999, 91.76, 91.84400000000001, 91.93499999999999, 91.771, 91.8, 91.80699999999999, 91.78099999999999, 91.791, 91.86699999999999, 91.822, 91.86399999999999], \"name\": \"Average Validation Accuracy\", \"mode\": \"lines+markers\", \"marker\": {\"color\": \"Red\", \"size\": 10}}], {\"title\": \"Validating a Model\", \"xaxis\": {\"title\": \"Number of Ephochs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"11754037-97e5-4cd4-ba29-f18727b856d7\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"11754037-97e5-4cd4-ba29-f18727b856d7\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.6, 87.42, 88.48, 89.15, 88.98, 89.12, 89.66, 90.05, 90.26, 90.81, 90.48, 90.66, 90.72, 91.17, 91.2, 90.97, 90.86, 91.28, 91.48, 91.42, 91.57, 91.08, 91.31, 90.99, 91.67, 91.1, 91.43, 91.65, 91.62, 91.45, 90.68, 91.27, 91.59, 91.83, 91.55, 91.68, 91.53, 91.75, 91.86, 91.64, 91.49, 91.59, 91.39, 91.66, 91.66, 91.36, 91.72, 91.64, 91.78, 91.83], \"name\": \"val_acc_run_1\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.48, 86.47, 87.74, 88.85, 89.18, 89.91, 89.81, 90.32, 89.61, 90.53, 90.57, 90.72, 89.68, 90.97, 90.74, 90.97, 90.95, 91.31, 90.56, 91.5, 91.22, 91.56, 91.29, 91.52, 91.38, 91.67, 91.47, 91.57, 91.61, 91.89, 91.41, 91.65, 91.74, 91.59, 91.68, 91.91, 91.85, 91.46, 91.67, 91.57, 91.72, 92.03, 91.88, 91.81, 91.78, 91.45, 91.83, 91.48, 91.79, 92.12], \"name\": \"val_acc_run_2\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.98, 87.01, 87.82, 88.85, 89.03, 90.1, 89.98, 90.12, 90.42, 90.47, 90.44, 90.75, 90.85, 90.97, 91.5, 91.56, 91.54, 90.87, 91.59, 91.91, 91.83, 91.84, 91.47, 91.78, 91.56, 91.67, 91.08, 91.55, 91.96, 91.97, 91.47, 91.91, 91.75, 91.72, 92.09, 91.71, 91.69, 91.91, 91.55, 91.8, 92.05, 92.0, 91.67, 91.69, 91.76, 92.06, 91.79, 92.12, 91.92, 91.64], \"name\": \"val_acc_run_3\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.4, 86.93, 87.58, 88.61, 88.44, 89.29, 89.44, 89.31, 90.38, 90.26, 90.78, 90.54, 90.65, 90.98, 90.77, 90.93, 91.22, 90.71, 91.29, 90.37, 91.51, 91.37, 91.56, 91.55, 91.58, 91.47, 91.44, 91.61, 91.51, 91.66, 91.17, 91.83, 91.51, 91.62, 91.76, 91.46, 91.5, 91.83, 91.43, 91.9, 91.8, 91.71, 91.87, 91.79, 91.89, 91.98, 91.83, 91.57, 91.72, 91.43], \"name\": \"val_acc_run_4\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [85.19, 87.71, 88.44, 88.9, 88.92, 90.13, 90.29, 90.5, 90.36, 90.66, 90.73, 90.76, 91.03, 91.27, 91.56, 91.12, 91.36, 91.37, 91.36, 91.43, 91.64, 91.72, 91.61, 91.74, 91.83, 91.33, 91.51, 91.85, 91.95, 91.32, 91.97, 91.9, 91.62, 91.92, 91.39, 91.58, 91.8, 91.86, 91.96, 91.38, 92.13, 92.22, 92.23, 91.98, 92.12, 91.97, 91.5, 92.12, 92.0, 92.13], \"name\": \"val_acc_run_5\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.87, 86.09, 88.53, 88.89, 89.4, 89.65, 89.88, 89.79, 90.66, 89.96, 91.03, 91.22, 89.75, 91.25, 91.2, 91.19, 91.6, 91.66, 91.26, 91.17, 91.51, 91.45, 91.42, 91.58, 91.56, 91.92, 91.63, 91.37, 91.3, 91.78, 91.71, 91.55, 91.67, 91.53, 91.8, 91.89, 91.88, 91.83, 91.91, 92.03, 92.09, 91.61, 91.81, 91.61, 91.51, 91.68, 91.6, 92.03, 91.75, 91.76], \"name\": \"val_acc_run_6\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.28, 86.92, 87.87, 89.08, 89.65, 89.5, 89.94, 89.97, 90.33, 90.92, 90.92, 90.9, 91.01, 90.13, 91.2, 91.65, 91.54, 91.13, 91.84, 91.69, 91.55, 91.57, 91.35, 91.72, 92.0, 91.6, 91.81, 92.05, 92.03, 91.88, 92.0, 92.03, 91.22, 91.9, 91.47, 92.13, 92.15, 91.91, 92.18, 91.78, 92.11, 92.26, 91.97, 91.8, 92.13, 92.06, 91.88, 92.02, 91.59, 92.04], \"name\": \"val_acc_run_7\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [83.91, 86.36, 87.78, 88.86, 89.3, 89.82, 89.8, 90.13, 90.23, 90.62, 90.88, 91.03, 90.77, 91.06, 91.03, 91.01, 91.47, 91.21, 91.56, 91.67, 91.36, 91.53, 91.87, 91.62, 91.39, 91.5, 91.73, 91.97, 92.07, 92.03, 91.47, 91.87, 92.03, 91.85, 92.0, 91.77, 91.87, 92.09, 91.83, 91.83, 91.82, 92.02, 91.87, 92.2, 92.01, 91.72, 91.88, 91.82, 92.12, 92.03], \"name\": \"val_acc_run_8\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [83.53, 86.22, 88.09, 88.77, 89.22, 89.38, 89.48, 89.82, 90.33, 90.75, 90.8, 90.55, 91.09, 90.92, 90.92, 90.83, 90.81, 91.43, 91.36, 91.68, 91.64, 91.43, 91.84, 91.54, 91.6, 91.61, 91.62, 90.97, 91.77, 91.45, 91.51, 91.92, 91.88, 91.6, 91.84, 91.7, 91.66, 91.77, 92.04, 91.95, 91.51, 92.04, 91.14, 91.77, 91.66, 91.92, 91.92, 92.12, 91.77, 91.77], \"name\": \"val_acc_run_9\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.53, 86.72, 87.87, 88.76, 88.93, 89.85, 90.06, 90.08, 90.53, 90.63, 90.42, 90.83, 90.89, 90.79, 91.1, 91.38, 91.2, 91.27, 91.47, 91.43, 91.2, 91.67, 91.45, 91.51, 91.61, 91.47, 91.52, 91.46, 91.55, 91.73, 91.64, 91.93, 91.72, 91.51, 91.57, 91.87, 91.76, 91.74, 91.94, 91.72, 91.72, 91.87, 91.88, 91.69, 91.55, 91.61, 91.96, 91.75, 91.78, 91.89], \"name\": \"val_acc_run_10\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [84.477, 86.785, 88.02, 88.872, 89.10499999999999, 89.675, 89.83399999999999, 90.009, 90.311, 90.561, 90.70499999999998, 90.79599999999999, 90.64399999999999, 90.951, 91.122, 91.161, 91.25500000000002, 91.224, 91.37700000000001, 91.42699999999999, 91.503, 91.52200000000002, 91.51700000000002, 91.55499999999999, 91.618, 91.534, 91.52399999999999, 91.605, 91.737, 91.71600000000001, 91.50300000000001, 91.78599999999999, 91.673, 91.70700000000001, 91.715, 91.77000000000001, 91.76899999999999, 91.815, 91.83699999999999, 91.76, 91.84400000000001, 91.93499999999999, 91.771, 91.8, 91.80699999999999, 91.78099999999999, 91.791, 91.86699999999999, 91.822, 91.86399999999999], \"name\": \"Average Validation Accuracy\", \"mode\": \"lines+markers\", \"marker\": {\"color\": \"Red\", \"size\": 10}}], {\"title\": \"Validating a Model\", \"xaxis\": {\"title\": \"Number of Ephochs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(1,11,50)\n",
    "plots(2,11,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_accuracy_plot(df):\n",
    "    trace_train, trace_val, trace_test = {}, {}, {}\n",
    "    \n",
    "    tarce_acc = []\n",
    "    trace_train = {'type'    : 'scatter',\n",
    "                   'x'       : model_final_acc.index,\n",
    "                   'y'       : model_final_acc['Training Accuracy'].values,\n",
    "                   'name'    : 'Training Accuracy'}\n",
    "    tarce_acc.append(trace_train)\n",
    "    #print(trace_train)\n",
    "    \n",
    "    trace_val =   {'type'    : 'scatter',\n",
    "                   'x'       : model_final_acc.index,\n",
    "                   'y'       : model_final_acc['Validation Accuracy'].values,\n",
    "                   'name'    : 'Validation Accuracy'}\n",
    "    tarce_acc.append(trace_val)\n",
    "    #print(trace_val)\n",
    "    \n",
    "    trace_test =   {'type'    : 'scatter',\n",
    "                   'x'       : model_final_acc.index,\n",
    "                   'y'       : model_final_acc['Testing Accuracy'].values,\n",
    "                   'name'    : 'Testing Accuracy'}\n",
    "    tarce_acc.append(trace_test)\n",
    "        \n",
    "    data = Data(tarce_acc)\n",
    "    layout = {'title' :  ' Accuracies',\n",
    "              'xaxis' : {'title' : 'Number of Runs'},\n",
    "              'yaxis' : {'title' : 'Accuracy'},\n",
    "              \"width\" : 1200,\n",
    "              \"height\" :600\n",
    "              }\n",
    "    fig = Figure(data = data, layout = layout)\n",
    "\n",
    "    pyo.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "Training Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          93.35,
          93.01,
          93.22,
          92.89,
          93.33,
          92.92,
          93.31,
          93.19,
          93.41,
          93.33
         ]
        },
        {
         "name": "Validation Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          91.83,
          92.12,
          91.64,
          91.43,
          92.13,
          91.76,
          92.04,
          92.03,
          91.77,
          91.89
         ]
        },
        {
         "name": "Testing Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          92.31,
          92.45,
          91.77,
          91.92,
          92.08,
          92.25999999999999,
          92.13,
          92.17,
          92.36,
          92.14
         ]
        }
       ],
       "layout": {
        "height": 600,
        "title": " Accuracies",
        "width": 1200,
        "xaxis": {
         "title": "Number of Runs"
        },
        "yaxis": {
         "title": "Accuracy"
        }
       }
      },
      "text/html": [
       "<div id=\"880d80a6-7b75-476f-9a47-f6d0ea5032fd\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"880d80a6-7b75-476f-9a47-f6d0ea5032fd\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [93.35, 93.01, 93.22, 92.89, 93.33, 92.92, 93.31, 93.19, 93.41, 93.33], \"name\": \"Training Accuracy\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [91.83, 92.12, 91.64, 91.43, 92.13, 91.76, 92.04, 92.03, 91.77, 91.89], \"name\": \"Validation Accuracy\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [92.31, 92.45, 91.77, 91.92, 92.08, 92.25999999999999, 92.13, 92.17, 92.36, 92.14], \"name\": \"Testing Accuracy\"}], {\"title\": \" Accuracies\", \"xaxis\": {\"title\": \"Number of Runs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"880d80a6-7b75-476f-9a47-f6d0ea5032fd\" style=\"height: 600px; width: 1200px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"880d80a6-7b75-476f-9a47-f6d0ea5032fd\", [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [93.35, 93.01, 93.22, 92.89, 93.33, 92.92, 93.31, 93.19, 93.41, 93.33], \"name\": \"Training Accuracy\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [91.83, 92.12, 91.64, 91.43, 92.13, 91.76, 92.04, 92.03, 91.77, 91.89], \"name\": \"Validation Accuracy\"}, {\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [92.31, 92.45, 91.77, 91.92, 92.08, 92.25999999999999, 92.13, 92.17, 92.36, 92.14], \"name\": \"Testing Accuracy\"}], {\"title\": \" Accuracies\", \"xaxis\": {\"title\": \"Number of Runs\"}, \"yaxis\": {\"title\": \"Accuracy\"}, \"width\": 1200, \"height\": 600}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_accuracy_plot(model_final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.35</td>\n",
       "      <td>91.83</td>\n",
       "      <td>92.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.01</td>\n",
       "      <td>92.12</td>\n",
       "      <td>92.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.22</td>\n",
       "      <td>91.64</td>\n",
       "      <td>91.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.89</td>\n",
       "      <td>91.43</td>\n",
       "      <td>91.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93.33</td>\n",
       "      <td>92.13</td>\n",
       "      <td>92.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92.92</td>\n",
       "      <td>91.76</td>\n",
       "      <td>92.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.31</td>\n",
       "      <td>92.04</td>\n",
       "      <td>92.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.19</td>\n",
       "      <td>92.03</td>\n",
       "      <td>92.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93.41</td>\n",
       "      <td>91.77</td>\n",
       "      <td>92.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93.33</td>\n",
       "      <td>91.89</td>\n",
       "      <td>92.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training Accuracy  Validation Accuracy  Testing Accuracy\n",
       "1               93.35                91.83             92.31\n",
       "2               93.01                92.12             92.45\n",
       "3               93.22                91.64             91.77\n",
       "4               92.89                91.43             91.92\n",
       "5               93.33                92.13             92.08\n",
       "6               92.92                91.76             92.26\n",
       "7               93.31                92.04             92.13\n",
       "8               93.19                92.03             92.17\n",
       "9               93.41                91.77             92.36\n",
       "10              93.33                91.89             92.14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Accuracy      93.196\n",
       "Validation Accuracy    91.864\n",
       "Testing Accuracy       92.159\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final_acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg_tranining_acc 93.196 %\n",
      "Avg_validation_acc 91.86399999999999 %\n",
      "Avg_testing_acc 92.15899999999999 %\n"
     ]
    }
   ],
   "source": [
    "Avg_tranining_acc, Avg_validation_acc, Avg_testing_acc  = model_final_acc.mean()\n",
    "\n",
    "print('Avg_tranining_acc {} %'.format(Avg_tranining_acc))\n",
    "print('Avg_validation_acc {} %'.format(Avg_validation_acc))\n",
    "print('Avg_testing_acc {} %'.format(Avg_testing_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final_acc.to_csv('Fina_Accuracy.csv')\n",
    "train_val_acc.to_csv('Training_Validation_accuracies_each_run.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
